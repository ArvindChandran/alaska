{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using trained tile detectors to extract feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import sys\n",
    "home = os.path.expanduser(\"~\")\n",
    "user = home.split('/')[-1]\n",
    "sys.path.append(home + '/alaska_github/src/')\n",
    "from tools.tf2onnx_utils import *\n",
    "from tools.models import *\n",
    "from tools.train_estimator import *\n",
    "from tools.jpeg_utils import *\n",
    "from tools.tf_utils import *\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QF = 95\n",
    "checkpoint_prefix = home + '/alaska_github/models/feature_extractors/QF'+str(QF)+'/tensorflow/'\n",
    "checkpoint_path = checkpoint_prefix + 'model.cpkt-color_separated'\n",
    "data_prefix = home + '/alaska_github/data/QF'+str(QF)+'/arbitrary_size/'\n",
    "data_dict = {'COVER':data_prefix+'JPEG/COVER/',\n",
    "            'JUNI':data_prefix+'JPEG/JUNI/',\n",
    "            'UED':data_prefix+'JPEG/UED/',\n",
    "            'NSF5':data_prefix+'JPEG/NSF5/',\n",
    "            'EBS':data_prefix+'JPEG/EBS/'}\n",
    "output_dict = {'COVER':data_prefix+'FEATURE_MAPS/COVER/',\n",
    "            'JUNI':data_prefix+'FEATURE_MAPS/JUNI/',\n",
    "            'UED':data_prefix+'FEATURE_MAPS/UED/',\n",
    "            'NSF5':data_prefix+'FEATURE_MAPS/NSF5/',\n",
    "            'EBS':data_prefix+'FEATURE_MAPS/EBS/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yyousfi1/alaska_github/src/tools/models.py:59: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yyousfi1/alaska_github/src/tools/models.py:64: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/yyousfi1/alaska_github/models/feature_extractors/QF95/tensorflow/model.cpkt-color_separated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.52s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "model_class = SR_net_feature_extractor_beast\n",
    "tf.reset_default_graph()\n",
    "input_image = tf.placeholder(tf.float32, shape=[1, None, None, 3], name='input')\n",
    "global_step = tf.get_variable('global_step', dtype=tf.int32, shape=[], initializer=tf.constant_initializer(0), trainable=False)\n",
    "featuremaps = model_class(input_image,  tf.estimator.ModeKeys.PREDICT)\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "saver_all = tf.train.Saver(max_to_keep=10000)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    saver_all.restore(sess, checkpoint_path)\n",
    "    for key in data_dict.keys():\n",
    "        im_names = os.listdir(data_dict[key])\n",
    "        if not os.path.exists(output_dict[key]):\n",
    "            os.makedirs(output_dict[key], 0o755)\n",
    "        for im_name in tqdm(im_names):\n",
    "            tmp = jpeglib.jpeg(data_dict[key]+im_name, verbosity=0)\n",
    "            image = decompress(tmp)\n",
    "            f = sess.run(featuremaps, feed_dict = {input_image: image})\n",
    "            f_dict = dict()\n",
    "            for i,branch in enumerate(['YCrCb', 'CrCb', 'Y', 'Cr', 'Cb']):\n",
    "                f_dict[branch] = f[i,:,:]\n",
    "            with open(output_dict[key]+im_name.split('.jpg')[0]+'.p', 'wb') as handle:\n",
    "                pickle.dump(f_dict, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These feature maps can now be used to train a classifier. In [1],the authors chose a MLP with 2 Hidden  Layers.\n",
    "\n",
    "We encourage trying different classifiers (e.g. from scikit-learn libreary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using frozen MLP to steganalyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frozen MLP provided in this repository corresponds to row 10 in Table 3 in [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix/Placeholder\n",
      "prefix/Flatten/flatten/Reshape/shape\n",
      "prefix/Flatten/flatten/Reshape\n",
      "prefix/layer_1/weights\n",
      "prefix/layer_1/weights/read\n",
      "prefix/layer_1/biases\n",
      "prefix/layer_1/biases/read\n",
      "prefix/layer_1/MatMul\n",
      "prefix/layer_1/BiasAdd\n",
      "prefix/layer_1/Relu\n",
      "prefix/layer_2/weights\n",
      "prefix/layer_2/weights/read\n",
      "prefix/layer_2/biases\n",
      "prefix/layer_2/biases/read\n",
      "prefix/layer_2/MatMul\n",
      "prefix/layer_2/BiasAdd\n",
      "prefix/layer_2/Relu\n",
      "prefix/layer_3/weights\n",
      "prefix/layer_3/weights/read\n",
      "prefix/layer_3/biases\n",
      "prefix/layer_3/biases/read\n",
      "prefix/layer_3/MatMul\n",
      "prefix/layer_3/BiasAdd\n",
      "prefix/output\n"
     ]
    }
   ],
   "source": [
    "graph = load_graph(home + '/alaska_github/models/detectors/QF95/tensorflow/MLP_frozen.pb')\n",
    "# Checking the operations names\n",
    "for op in graph.get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = graph.get_tensor_by_name('prefix/Placeholder:0')\n",
    "y = graph.get_tensor_by_name('prefix/output:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted as: JUNI\n"
     ]
    }
   ],
   "source": [
    "test_file = output_dict['JUNI']+'iPAD-pro-7.1-13inch_2065.jpg'.split('.jpg')[0]+'.p'\n",
    "with open(test_file, 'rb') as handle:\n",
    "    test_feature_map = pickle.load(handle)\n",
    "branches = ['Y' ,'YCrCb', 'CrCb']   \n",
    "stego_schemes = ['EBS', 'JUNI', 'NSF5', 'UED']\n",
    "test_feature_map = np.expand_dims(np.concatenate([test_feature_map[branch].reshape(-1) for branch in branches]),0)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    logits = sess.run(y, feed_dict={x: test_feature_map})\n",
    "    \n",
    "print('predicted as:', stego_schemes[np.argmax(softmax(logits))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] Yousfi, Yassine, et al. \"Breaking ALASKA: Color separation for steganalysis in JPEG domain.\" Proceedings of the ACM Workshop on Information Hiding and Multimedia Security. ACM, 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
